\chapter{Technologia CUDA}
\section{Współbieżna przyszłość}
Kiedy w roku 2005 Herb Sutter \cite{lunch} opublikował artykuł o intrygująco 
brzmiącej nazwie 'Koniec darmowego lanczu', w szeroko pojętym środowisku 
deweloperskim rozgorzała dyskusja. Autor stwierdził, że obserwujemy kres 
wykładniczego wzrostu wydajności mikroprocesorów, rozumianego przez wzrost 
częstotliwości taktowania ich zegarów w zależności od ilości użytych
tranzystorów. Z tym argumentem, nie można się nie zgodzić patrząc na
oferowane na rynku procesory firmy Intel przedstawione na rysunku \ref{proce}.

\begin{figure}[ht]
\centering
\includegraphics[scale=1.0]{images/CPU.png}
\caption{Charakterystyki procesorów firmy Intel na przestrzeni 40 lat. Źródło: http://www.gotw.ca/}
\label{proce}
\end{figure}

Ważniejszą jednak tezą postawioną przez Suttera było stwierdzenie, że
programiści nie będą mogli dłużej korzystać ze wzrostu mocy obliczeniowej
sprzętu. Taki wzrost wydajności często okazywał się dla twórców aplikacji
niezastąpiony. Napotykając problemy wydajnościowe w swoim oprogramowania
programiści mogli albo poświęcić się żmudnemu procesowi optymalizacji, albo
po prostu podnieść jej wymaganie sprzętowe. Często, głównie ze względów
ekonomicznych drugi wariant było wybierany, gdyż ograniczał się do tylko do
poczekania na nowe generacje sprzętu. To zjawisko, ciekawie scharakteryzował J.
Spolsky przytaczany w \cite{nolunch} ,,Jako programista masz wybór, albo
spędzisz pół roku na przedesignowaniu swojej aplikacji, wstawiając kod asemblera
w krytycznych sekcjach, albo na wakacjach, grając na perkusji w rockowej kapeli.
Niezależnie od alternatywy którą wybierzesz, twoja aplikacji będzie działała
szybciej,,.

Czy jednak założenie o niskim wzroście wydajności współczesnym mikroprocesorów
jest prawdziwe? Wprawdzie częstotliwość taktowania nie podlega już takim trendom
co wcześniej, jednak dzisiejsze architektury CPU oferują więcej niż jeden rdzeń
zdolny do wykonywania programu. Obecnie na rynku jest już oferowany procesor
Intel z serii i7, który może posiadać do 8 fizycznych rdzeni. Dodatkowo, nowe
technologie takie jak hyperthreading, pipelining czy zaawansowany branch
prediction pozwalają na możliwie szybkie, czy wręcz równoległe wykonywanie
fragmentów sekwencyjnego kodu.

Mimo nowoczesnej architektury CPU, sekwencyjnie programy i tak wykonywane są
tylko na pojedynczym rdzeniu\cite{massive}, który jak było to opisane wcześniej,
na przestrzeni ostatnich lat stał się znacząco szybszy. Nawet 
procesory posiadające instrukcje typu SIMD oraz heurystyki wykorzystywane w
nowoczesnych kompilatorach, takie jak np. 'Loop Vectorizer' wykorzystywany w
kompilatorach bazujących na LLVM \cite{llvm} czy 'Auto-Vectorization' w GCC
\cite{gcc} nie są w stanie zamienić sekwencyjnego kodu w wydajny kod
współbieżny.

Sutter stwierdza, że odpowiedzą na postawiony wyżej problem jest zmiana
paradygmatu z programowania sekwencyjnego na współbieżne. Tworzone wielowątkowe
aplikacje będą w stanie korzystać z wielordzeniowych architektur, co przyspieszy
ich wykonywanie a programistom pozwoli nadal oczekiwać na ,,darmowy lancz''.
Faktem potwierdzającym postawioną przez niego tezę jest rysunek \ref{gflops},
przedstawiający teoretyczną maksymalną wydajność wielo-rdzeniowych mikroprocesorów oraz układów
graficznych mierzoną w giga FLOPS-ach (operacji zmiennoprzecinkowych na
sekundę).

\begin{figure}[ht]
\centering
\includegraphics[scale=0.4]{images/floating-point-operations-per-second.png}
\caption{Teoretyczna wydajność mierzona w GFLOP/s w czasie. Źródło: CUDA C Programming Guide}
\label{gflops}
\end{figure}

Samo jednak przejście na model programowania równoległego nie będzie łatwe,
przyjemne, a przede wszystkim tanie. Wg
Suttera taka zmiana wiązać się będzie nie tylko ze zmianą architektury
aplikacjiczy konstrukcjami języków programowania. 

Zmiany w stronę wielowątkowości obserwowane są od jakiegoś czasu. Dla przykładu
w 
standardzie języka C++ 11, biblioteka obsługująca wątki będzie wchodzić w skład
biblioteki standardowej, Microsoft publikuje bibliotekę C++ AMP i wielowątkowe
wersje popularnych bibliotek dla Platformy .NET jak PLINQ, a NVIDIA biblioteki
algorytmiczne m.in. CUFFT wykonywane na GPU. Marsz w stronę wielowątkowości
obserwujemy cały czas, ale moim zdaniem nie będzie to jednak rewolucja
zapowiadana w \cite{rewolucja}, lecz bardziej ewolucja. Warto dodać, że dużo
pracy zostało już wykonane.  Serwery www oraz bazy danych są świetnym przykładem
dobrze skalowanych, wielowątkowych aplikacji.

Kolejną istotną kwestią w projektowaniu wielowątkowych aplikacji jest jej
skalowalność. Jeżeli dany problem programistyczny nie może być
dynamicznie dzielony na podproblemy, które będą mogły być rozwiązane
indywidualnie, korzyści związane z przyrostem ilości rdzeni w sprzęcie nie będą
zauważalne. Taki podział często okazuje się być nietrywialny, a czasem
wręcz niemożliwy. Nie można też oczekiwać wielkich wzrostów wydajności, ponieważ nie
cały kod aplikacji może być zrównoleglony. Dobrze opisuje to formuła stworzona w
1967 r. przez G. Amdahla:

\begin{equation}
W(N) = \frac{1}{(1-S) + \frac{S}{N}}
\end{equation}
,gdzie $N$ jest ilością jednostek wykonywania, a $S$ jest częścią kodu programu,
	który może być zrównoleglony. I tak dla 8 rdzeni i programu o współczynniku
	$S=60\%$, otrzymujemy wzrost wydajności tylko około 2.1 raza.

Współbieżność jest bez wątpienia problemem z którym każdemu programiście
przyjdzie się kiedyś zmierzyć. Możliwe, że do niektórych problemów wystarczą mu
gotowe rozwiązania z dostępnych bibliotek, jednak myślenie o problemie i
przedstawienie go w postaci dającej się zrównoleglić będzie rzeczą
najważniejszą. Środowiska naukowe pomagają w tym aspekcie bardzo istotnie.
Każdego roku publikowane są artykuły przedstawiające często nowatorskie
podejścia do standardowych problemów, wskazując możliwość ich współbieżnego rozwiązania.
Oczekuję, że w następnych latach trend z programowaniem równoległym będzie
przybierał na sile, czego owocem będą nowe, innowacyjne metody i technologie.

\section{Powstanie CUDA}

Technologia CUDA (Compute Unified Device Architecture) została po raz pierwszy
zaprezentowana przez NVIDIA w listopadzie 2006 r. Związana jest ona z nowym
modelem
programowania aplikacji w którym sekwencyjne fragmenty kodu są wykonywane na
CPU, natomiast te wymagające obliczeniowo, na procesorach graficznych (GPU).
Pierwsze karty graficzne z serii GeForce 8800, implementujące technologię CUDA,
		 pojawiły się w roku 2006 r. Programiści od tego czasu mogą korzystać ze
		 specjalnie zaprojektowanych w tym celów interfejsów programistycznych
		 bibliotek CUDA.

Sama koncepcja programowania procesorów graficznych jest znana od dawna.
Programiści używając interfejsów do programowania shaderów, dostępnych chociażby
w OpenGL 1.4 (2002) czy Direct3D 8.0 (2001), mogli dokonywać 
obliczeń na kartach graficznych. Wymagało to jednak często wielu trików, takich
jak przekazywanie danych poprzez tekstury czy odczytywania danych wyjściowych z
wygenerowanej ramki obrazu. NVIDIA wyszła naprzeciw tym problemom, tworząc
dedykowane do tego interfejsy programistyczne w języku C.

Na sukces technologi CUDA złożyło się wg \cite{massive} parę czynników.
Pierwszym jest fakt, że programiści aplikacji równoległych otrzymali środowisko
w którym ich kod, wg zapewnień NVIDIA, będzie wykonywany poprawnie, niezależnie
od używanego sprzętu. Ma to szczególnie ważne znaczenie, biorąc pod uwagę fakt,
   że projektanci kart graficznych nie zakładali początkowo ich użycia do
   obliczeń inżynierskich. I tak np. kalkulacje na liczbach zmiennoprzecinkowych
   na różnych kartach graficznych NVIDIA do 2006 r. mogły skutkować nieznacznie innymi
   wynikami. Dopiero specyfikacja technologii CUDA wymusiła na projektantach
   sprzętu zgodność ze standardami publikowanymi przez IEEE.

Kolejnym czynnikiem, który zdecydował o sukcesie technologii CUDA jest
dostępność medium, na którym wielowątkowe, zrównoleglone aplikacje mogą być
wykonywane. W chwili obecnej na rynku znajdują się setki milionów kart
graficznych wyprodukowanych przez NVIDIA zdolnych do wykonania kodu napisanego w
CUDA. Ma to bardzo istotny wymiar ekonomiczny, ponieważ wiele specjalistycznych
(np. w medycynie) aplikacji nie musi być dostarczana wraz z drogim,
	dedykowanym dla tego celu sprzętem. Spowodowało to zatem wzrost rynku dla
	tego typu rozwiązań i stworzyło ekonomiczne uzasadnienie do dalszej pracy
	nad współbieżnie wykonywanymi aplikacjami.

Ostatnim, najbardziej oczywistym czynnikiem, jest wzrost wydajności. Procesory
graficzne składające się z multiprocesorów strumieniowych są przystosowane do
przetwarzania dużej ilości danych jednocześnie. Dodatkowo narzut związany z
kreacją i zarządzaniem pojedynczego wątku na GPU jest znacząco mniejszy niż w
analogiczna operacja wykonana na CPU.  W nowych architekturach takich jak
GeForce z serii 680 posiadającą aż 1536 rdzeni zdolnych do równoległego
wykonywania kodu.  Efektem tego może być wzrost wydajności aplikacji w
niektórych zastosowaniach nawet do 150 razy \cite{prez}.

\section{Interfejs programisty}

\subsection{Kompilacja}

Zaproponowany we frameworku CUDA model programowania zakłada możliwość
skompilowania i wykonywania kodu programu w dwóch różnych kontekstach -
gospodarza (CPU) oraz GPU (procesora graficznego)\cite{Nvillb}. Jako kontekst rozumiany jest
specyficzny dla danej architektury zestaw instrukcji dla procesora. Fragmenty
programu, których zrównoleglenie jest niemożliwe są tworzone w kontekście
gospodarza,
	natomiast te wymagające intensywnych, wielowątkowych obliczeń w kontekście
	GPU.  Współistnienie dwóch kontekstów w jednym programie wykonywalnym
	możliwe jest dzięki zestawie bibliotek i narzędzi dostarczanych wraz z
	pakietem CUDA.

Biblioteki dostarczane wraz z pakietem CUDA umożliwiają pisanie kodu CUDA w różnych
językach programowania. Najczęściej stosowanych jest język C, istnieją jednak biblioteki
dla języków C++, Java, Python, C czy Fortran. Dodatkowo kod CUDA może być też pisany w specjalnie stworzonym do tego celu
niskopoziomowym języku PTX (Pararell Thread Execution), przypominającym asembler.
Cechą wyróżniającą kod PTX od skompilowanego kodu binarnego, jest możliwość jego
kompilacji w locie z użyciem tzw. kompilatora JIT (ptxas) dostarczanego przez
NVIDIĘ wraz ze sterownikami do karty graficznej. Pozwala to na uruchamianie kodu
CUDA nie tylko na różnych wersjach sterowników karty graficznej, lecz również na
innych procesorach graficznych firmy NVIDIA bez potrzeby rekompilacji.

\begin{figure}[ht]
\centering
\input{images/cuda}
\caption{Stos CUDA. Źródło: Opracowanie własne.}
\label{cuda-model}
\end{figure}

CUDA to w rzeczywistości cały stos bibliotek, sterowników i narzędzi. Jest on
ogólnie 
przedstawiony na rysunku \ref{cuda-model}. Najważniejszymi elementami w całym
stosie jest sterownik dostarczany przez producenta karty graficznej
oraz biblioteka CUDA Runtime (cudart). Zadaniem sterownika, uruchomionego
jako moduł jądra systemu operacyjnego, jest dostęp do urządzenia oraz wykonanie
na nim kodu dedykowanego dla jego architektury i wersji. Sterownik odpowiada za
komunikację z urządzeniem a biblioteka CUDA Runtime nadbudowuje nad nim wyżej
poziomowe funkcje takie jak inicjalizacja, wywołanie kontekstu GPU czy
kopiowanie danych między kartą a pamięcią RAM komputera.

Niezależnie od wybranego języka programowania czy użytych bibliotek, ostatecznie kod programu CUDA musi
zostać skompilowany do postaci binarnej i uruchomiony w kontekście gospodarza. W
czasie działania programu wykonywanego sekwencyjnie na CPU, następuje zmiana
kontekstów i uruchomienie skompilowanych fragmentów kodu na procesorze graficznym.
Przełączanie kontekstów jest transparentne dla programisty,
ponieważ ogranicza się tylko do wywołania odpowiednich funkcji z bibliotek
dostarczanych wraz z pakietem CUDA.

CUDA to nie tylko zestaw bibliotek, lecz również zestaw rozszerzeń do języka
programowania C. Implementacja rozszerzeń podytkowana była potrzebą
jednoznacznego rozróżnienia fragmentów programu każdego z kontekstów w kodzie
źródłowym. W rezultacie dzięki narzędziom można pisać kod CUDA używając ANSI C
oraz specjalnych rozszerzeń przypominających atrybuty kompilatora. W ten sposób
NVIDIA zaoszczędziła programistom CUDA potrzeby nauki nowego języka
programowania, czy pisania kodu w niskopoziomowym języku PTX. Użycie
specjalistycznych atrybutów kompilacji dla języka C, możliwe jest tylko dzięki
wykorzystaniu dostarczanego wraz z frameworkiem CUDA kompilatora 'nvcc'.

NVIDIA Cuda Compiler (nvcc) nie jest kompilatorem w tradycyjnym tego słowa
znaczeniu, a bardziej zestawem narzędzi służących do kompilacji. W przypadku gdy
kod źródłowy będzie kompilowany tylko w kontekście gospodarza, właściwą kompilacją
zajmują się kompilatory dedykowane dla danego systemu operacyjnego. I tak dla
Windows, nvcc wykorzystuje kompilator Visual Studio, natomiast dla systemu Linux
użyty jest m.in. GCC. Zadaniem NVCC jest ukrycie przed programistą etapów kompilacji
specyficznego kodu CUDA dla konkretnej implementacji, którą jest procesor
graficzny. Schemat kompilacji wraz z poszczególnymi etapami przedstawia rysunek
\ref{compilation}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{images/nvcc-options-for-separate-compilation.png}
\caption{Schemat rozłącznej kompilacji przy użyciu NVCC. Źródło: CUDA Compiler Driver NVCC}
\label{compilation}
\end{figure}

Pliki źródłowe programu napisanego w języku C zawierające rozszerzenia CUDA, przyjęło się zwyczajowo
oznaczać przyrostkiem ".cu", aby odróżnić je od konwencjonalnych programów C
oznaczanych przyrostkiem ".c". Oba rodzaje rozszerzeń są akceptowane przez NVCC, co
pozwala na wykorzystanie do kompilacji projektów CUDA tylko jednego kompilatora.
W celu ułatwienia procesu budowania NVCC wspiera większość tradycyjnych
parametrów kompilatora znanych z GCC czy Visual Studio Compiler. 

NVCC używane jest zazwyczaj do kompilacji kodu źródłowego do postaci binarnej.
Możliwe jest także użycie kompilatora do kompilacji kodu napisanego w C do
postaci pośrednich takich jak PTX, fatbin czy cubin. Fatbin jest plikiem
zawierającym kod PTX w wersjach dla różnych architektur kart graficznych.  W
momencie kompilacji w locie (JIT) sterownik karty graficznej potrafi z pliku
fatbin wybrać ten kod PTX, który najlepiej odpowiada jego wersji i modelowi
karty graficznej. Skutkuje to wyborem zoptymalizowanego dla danej architektury
kodu oraz skróceniem czasem ładowania aplikacji. Natomiast Cubin jest to plik
binarny przeznaczony dla konkretnego procesora graficznego, który nie jest
kompatybilny z innymi architekturami procesorów graficznych.

\subsection{Kernele}
Z punktu widzenia programisty wykonanie fragmentu kodu w kontekście GPU'a
ogranicza się do wywołania specyficznego rodzaju funkcji, nazywanego w nomenklaturze CUDA kernelami.
Kernele we języku C oznaczone są specjalnym atrybutem kompilatora
\texttt{\_\_global\_\_} oraz mają
specyficzną konwencję wywołania przedstawioną na listingu \ref{kernel}.

Funkcja kernela wykonywana jest na procesorze graficznym jednocześnie przez $M$
różnych wątków. W celu określenia dokładnej ilości wątków dla których ma się ona
wykonać oraz sposobu ich indeksowania, dwa dodatkowe parametry
są przekazane do funkcji kernela między znacznikami $<<<$ oraz $>>>$. Pierwszy parametr
oznacza ilość tzw. bloków, czyli 1, 2 lub 3 - wymiarowych grup ograniczających
wątki. Drugi parametr to wymiar pojedynczego bloku, określany jako pojedyncza liczba
całkowita lub specjalnym typ $dim3$, służący do określenia rozmiarów 2 lub
3-wymiarowego bloku. Po zdefiniowaniu ilości i wielkości bloków indeksy wątków dostępne
są w ciele funkcji dzięki predefiniowanej zmiennej $threadIdx$.

\begin{lstlisting}[caption=Dodawanie macierzy, label=kernel]
// Definicja funkcji kernela
__global__ void MatAdd(float A[N][N], float B[N][N],
		float C[N][N])
{
	int i = blockIdx.x * blockDim.x + threadIdx.x;
	int j = blockIdx.y * blockDim.y + threadIdx.y;
	if (i < N && j < N)
		C[i][j] = A[i][j] + B[i][j];
}

int main()
{
	...
	// Wywolanie kernela CUDA na bloku o wymiarach 16x16
	dim3 threadsPerBlock(16, 16);
	dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y);
	MatAdd<<<numBlocks, threadsPerBlock>>>(A, B, C);
	...
}
\end{lstlisting}

Grupę bloków zleconą do wykonania dla CUDA nazywa się siatką
(grid). Ogólny schemat siatki przedstawia rysunek \ref{grid}. Podobnie jak
wątki, bloki mogą być indeksowane jedno lub dwuwymiarowo. Ich indeksy są dostępne
w funkcji kernela pod specjalną zmienną $blockIdx$, natomiast rozmiar samego
bloku możliwy jest do pobrania poprzez zmienną $blockDim$.

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{images/grid-of-thread-blocks.png}
\caption{Źródło: CUDA Programming Guide}
\label{grid}
\end{figure}

Specyfikacja CUDA gwarantuje, że pojedynczy blok wykonywany jest na
dokładnie jednym procesorze graficznym. W efekcie, wątki wchodzące w
skład danego bloku wykonywane są sprzętowo współbieżnie. Same bloki zaś w zależności od
możliwości obliczeniowych urządzenia wykonywane są również
współbieżnie na procesorze graficznym lub w przypadku braku zasobów -
sekwencyjnie, czyli dopiero po
zakończeniu wykonywania poprzedzającego bloku. Taki model programowania zapewnia
skalowalność rozwiązania w przypadku posiadania przez urządzenie więcej niż
jednego procesora graficznego oraz pozwala programiście skupić się na
optymalizacji wykonania programu w ramach pojedynczego bloku, zostawiając frameworkowi CUDA.
zadanie optymalnej alokacji bloków między dostępne procesory 
 Programy pisane w CUDA muszą więc uwzględniać fakt,
że bloki mogę być wykonywane w dowolnej kolejności. 


\begin{lstlisting}[caption=Funkcje CUDA, label=cudafunc]
// Definicja funkcji
__device__ float square(float a)
{
	return a * a;
}
\end{lstlisting}

Definicja kernela nie jest jedynym rozszerzeniem do języka C dostępnym w
kompilatorze NVCC. Możliwa jest również definicja funkcji wykonywanej w
kontekście GPU poprzez oznaczenie jej atrybutem \texttt{\_\_device\_\_} (listing
		\ref{cudafunc}). Tak zdefiniowana funkcja może być użyta w funkcji
kernela, pozwalając na enkapsulację często powtarzanych fragmentów kodu. Należy
jednak pamiętać, że kontekst gospodarza i GPU znacząco się od siebie różnią i w
przypadku tego drugiego wywołania funkcji z reguły trwają dużo
dłużej\cite{Nvillb} Kompilator NVCC na ogół stara się więc inlinować wszystkie
funkcje oznaczone atrybutem \texttt{\_\_device\_\_}, czyli umieszcza ich kod
bezpośrednio w miejscu wywołania. Wydłuża to docelowy kod kernela , jednak
znacząco przyspiesza jego wykonywanie. W celu wymuszenia na kompilatorze braku
inlinowania trzeba poprzedzić atrybut \texttt{\_\_device\_\_} atrybutem
\texttt{\_\_noinline\_\_}, natomiast w celu zagwarantowania inlinowania funkcji
atrybutem \texttt{\_\_forceinline\_\_}.

\subsection{Hierarchia pamięci}

W modelu CUDA wyróżnia się 4 podstawowe typy pamięci:
\begin{itemize}
\item Rejestry
\item Pamięć Dzielona (Shared Memory)
\item Pamięć Stała (Const Memory)
\item Pamięć Globalna
\end{itemize}

Rejestry ogólnego przeznaczenia procesora graficznego są najszybszym rodzajem
pamięci dostępnej na GPU.  Ich ilość jest jednak mocno ograniczona, dlatego
programista CUDA musi poświęcić szczególną uwagę aby zapewnić możliwe dobre ich
wykorzystanie. Rejestry są najczęściej alokowane w przypadku tworzenia i
używania zmiennych tymczasowych. Dostęp do zmiennych lokalnie zdefiniowanych
możliwy jest tylko z jednego wątku, dlatego w celu wymiany informacji pomiędzy
wątkami zachodzi potrzeba użycia innego rodzaju pamięci.

Pamięć dzielona to szybka pamięć L1 służąca do wymiany danych między wątkami.
Z uwagi że cache L1 jest określony tylko dla danego procesora graficznego,
  pamięć ta może być współużytkowana tylko w ramach pojedynczego bloku. W celu
  deklaracji pamięci dzielonej NVCC wprowadza nowy atrybut o nazwie
  \texttt{\_\_shared\_\_}. Odwołania do pamięci dzielonej zajmuje parę razy
  więcej cykli zegara niż odwołanie do rejestru, jednak i tak liczba ta jest
  znacząco mniejsza od cykli potrzebnych do pobrania danych z pamięci globalnej.
  Wielkość pamięci dzielonej dostępnej na procesorze jest niewielka i dla
  architektury Kepler wynosi 48 KB.

Pamięć stała jest to w istocie pamięć L1 stworzona i używana do renderowania tekstur 
w grafice komputerowej. Ideą zastosowania tej pamięci jest zmniejszenie czasu
dostępu do danych mieszczących się z pamięci globalnej, których nie modyfikuje się w trakcie działania programu.
W tym celu użyty jest dodatkowy cache L1, który przechowuje kopię danych 
z pamięci globalnej i dostępny jest tylko w trybie do odczytu.
Aby zadeklarować zmienne tego typu, która może zostać odczytana z dowolnego
wątku, czy też bloku używa się atrybutu \texttt{\_\_constant\_\_}.

Ostatnim rodzajem pamięci wykorzystywanej w modelu CUDA jest pamięć globalna.
Jest to pamięć typu DRAM o znacznej pojemności, wynoszącej na chwilę pisania tej
pracy, nawet do 4 GB w najbardziej zaawansowanych kartach dostępnych na rynku. 
Wadą jej jest natomiast bardzo długi czas dostępu.

Schemat wątków i bloków z przypisaniem poszczególnych rodzajów pamięci do których
mają dostęp podsumowuje rysunek \ref{hier}.

\begin{figure}[ht]
\centering
\includegraphics[scale=0.8]{images/memory-hierarchy.png}
\caption{Hierarchia pamięci w modelu CUDA. Źródło: CUDA Programming Guide}
\label{hier}
\end{figure}

\section{GPU}


\begin{figure}[ht]
\centering
\includegraphics{images/gpu-devotes-more-transistors-to-data-processing.png}
\caption{Podział tranzystorów w architekturze CPU i GPU. Źródło: CUDA C Programming Guide}
\label{cpugpu}
\end{figure}

\subsection{Architektura procesorów graficznych}

Procesor graficzny mimo swojej coraz to bardziej zaawansowanej budowy nadal
znacząco różni się od architektury CPU. Przedstawia to rysunek \ref{cpugpu}, na
którym pokazany jest podział użytych tranzystorów pomiędzy logiczne moduły procesora.
Wynika z niego, że procesory graficzne posiadają mniejszą ilość pamięci cache oraz
mniej skomplikowane sterowanie przepływem instrukcji niż procesory firmy
Intel czy AMD. Wyróżniają się natomiast większą ilością jednostek arytmetyczno-logicznych
(ALU) dostępnych na układzie scalonym. Sprawia to, że procesory te są wyspecjalizowane w rozwiązywaniu
problemów wymagających dużej intensywności obliczeniowej mierzonej jako stosunek
operacji arytmetycznych do operacji na pamięci.

Współbieżne wykonywanie dużej ilości zadań możliwe jest dzięki implementacji
w procesorach graficznych architektury SIMT (Single Intruction Multiple Thread), która
przypomina architekturę SIMD używaną w współczesnych procesorach. W
odróżnieniu od SIMD, który udostępnia tylko możliwość równoległego wykonania danej
operacji na wektorze danych, SIMT umożliwia też równoległe wykonywanie wielu
niezależnych wątków. Zaletą wykonywania wątków, zamiast elementarnych operacji jest większa
elastyczność w sterowaniu przepływem programu. Każdy wykonywany wątek
na procesorze graficznym posiada własny licznik programu, dzięki czemu możliwe
jest wykonanie innych zestawów instrukcji procesora (tzw. branching).

W modelu CUDA zakłada się, że wszystkie wątki w ramach jednego bloku wykonywane
są równolegle. W rzeczywistości procesor graficzny potrafi współbieżnie wykonywać
instrukcje jedynie dla podzbioru wątków zwanych w nomenklaturze CUDA - warpem. 
Liczba wątków wchodzących w skład jednego warpa jest stała dla wszystkich stworzonych
do dziś architektur procesorów graficznych NVIDIA i wynosi 32. Z punktu
widzenia programisty fakt wykonywania tylko części wątków na raz może być
całkowicie pominięty, jednak jest niezbędny w przypadku dokonywania
optymalizacji na stworzonym kodzie CUDA\cite{kepler}.

W czasie wykonywania programu CUDA, każdy blok zostaje wpierw podzielony na odpowiednią
liczbę warpów, a następnie zlecony do wykonania przez jednostkę procesora zwaną warp
schedulerem. Wątki wchodzące w skład warpu mogą występować w jednym z dwóch stanów
- aktywnym, w którym to następna instrukcja wątku zostanie wykonana w następnym
cyklu zegara, oraz nieaktywnym - którego egzekucja zostaje w następnym cyklu
zawieszona. Warp scheduler jest w stanie wykonać serię instrukcji
procesora dla wszystkich wątków jednocześnie, a w przypadku gdy dla wątku
nastąpił conditional branching, oznaczany jest on jako nieaktywny i
zawiesza się wykonanie instrukcji programu dla jego danych. Jeżeli program CUDA
zawiera wyrażenie \texttt{if X {...} else {...}}, oznacza to, że najpierw zostaną
wykonane na 32 wątkach instrukcje programu pierwszej części wyrażenia,
		 z oznaczeniem jako nieaktywne tych wątków dla których wartość X jest
		 nieprawdziwa. Następnie druga strona wyrażenia zostanie wykonana na 32
		 wątkach w analogiczny sposób. Ważną implikacją działania warp
		 schedulera jest fakt, że dopiero po wykonaniu obu stron rozgałęzienia
		 programu następne instrukcje mogą być wykonane.


Procesor graficzny, zwany też multiprocesorem może być logicznie
podzielony na następujące elementy:
\begin{itemize}
\item rdzenie CUDA
\item 
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[scale=0.4]{images/memory-hierarchy2.png}
\caption{Hierarchia pamięci w architekturze Kepler: \cite{kepler}}
\label{hierarchiaKepler}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[scale=0.8]{images/gpu.png}
\caption{Źródło: CUDA Manual}
\end{figure}

\subsection{Device capabilities}
sasda
